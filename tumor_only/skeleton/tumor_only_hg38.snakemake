#################################
#
# snakefile for converting CIDR Sequencing data deliveries to non-PII ready for GRIS upload, running QC, and joint genotyping
#
# Susan Huse, susan.huse@nih.gov
# Frederick National Lab
# April 10, 2019
#
# Justin Lack
# Frederick National Lab
# December 11, 2019
#
# Mayank Tandon
# Frederick National Lab
# Feb, 2021
#
#################################
##### To dos:
## -- finish converting rules to not contain file paths (wherever possible)
## -- update cluster.json with appropriate settings for new rules!!
## -- Add more input/output path settings via config
## - should help with start-from-bam
## - will it work for adding arbirary vcfs (like from dragen)?
## -- GATK4 pre-processing
## -- Split all callers by chromosome?
## -- integrate into python-driven workflow like Skyler's RNA-Seek repo: https://github.com/skchronicles/RNA-seek/blob/main/rna-seek
## -- use containerized gatk4 via snakemake (require converting docker to singularity) https://github.com/skchronicles/RNA-seek/blob/7e2db2d4897e8c7a2c5cc5bba88c94fb63b5e642/workflow/rules/paired-end.smk#L25
## -- Use 'envmodules' to module load
## -- 
## ++ Purity estimates (--PureCN?--  > GATK4 CalculateContamination)
## - Ideally use same tool for tumor-normal or tumor-only
## - Can be additionally useful for passing to somatic variant valler (VarScan, e.g.)
## -- use nproc instead of biowulf cpus variable
## -- use nproc instead of biowulf cpus variable
## ++ VarScan
## ++ use containerized vcf2maf
##### 
## 
## Load python modules
##
import os
from os import listdir
# from os.path import join
import pandas as pd
import re
import sys
import glob
import datetime

## FROM: https://github.com/skchronicles/RNA-seek/blob/main/rna-seek
def rename(filename):
    """Dynamically renames FastQ file to have one of the following extensions: *.R1.fastq.gz, *.R2.fastq.gz
    To automatically rename the fastq files, a few assumptions are made. If the extension of the
    FastQ file cannot be infered, an exception is raised telling the user to fix the filename
    of the fastq files.
    @param filename <str>:
        Original name of file to be renamed
    @return filename <str>:
        A renamed FastQ filename
    """
    import re

    # Covers common extensions from SF, SRA, EBI, TCGA, and external sequencing providers
    # key = regex to match string and value = how it will be renamed
    extensions = {
        # Matches: _S[##]_R[12]_fastq.gz, _S[##]_R[12].fastq.gz, _R[12]_fq.gz; works for exome fqs from SF
        "_S[0-9]+_R1_001.f(ast)?q.gz$": ".R1.fastq.gz",
        "_S[0-9]+_R2_001.f(ast)?q.gz$": ".R2.fastq.gz",
        # Matches: _R[12]_fastq.gz, _R[12].fastq.gz, _R[12]_fq.gz, etc.
        ".R1.f(ast)?q.gz$": ".R1.fastq.gz",
        ".R2.f(ast)?q.gz$": ".R2.fastq.gz",
        # ".R1(?<!\.trimmed).f(ast)?q.gz$": ".R1.fastq.gz",
        # ".R2(?<!\.trimmed).f(ast)?q.gz$": ".R2.fastq.gz",
        # Matches: _R[12]_001_fastq_gz, _R[12].001.fastq.gz, _R[12]_001.fq.gz, etc.
        # Capture lane information as named group
        ".R1.(?P<lane>...).f(ast)?q.gz$": ".R1.fastq.gz",
        ".R2.(?P<lane>...).f(ast)?q.gz$": ".R2.fastq.gz",
        # Matches: _[12].fastq.gz, _[12].fq.gz, _[12]_fastq_gz, etc.
        "_1.f(ast)?q.gz$": ".R1.fastq.gz",
        "_2.f(ast)?q.gz$": ".R2.fastq.gz",
        ####
        # Matches: *.bam if it's not preceded by '.recal' (i.e. match '.bam' exactly)
        "(?<!\.recal)\.bam$": ".input.bam",
        "\.recal\.bam$": ".input.bam"
    }

    if filename.endswith('.R1.fastq.gz') or filename.endswith('.R2.fastq.gz'):
        # Filename is already in the correct format
        return filename

    converted = False
    for regex, new_ext in extensions.items():
        matched = re.search(regex, filename)
        if matched:
            # regex matches with a pattern in extensions
            converted = True
            # Try to get substring for named group lane, retain this in new file extension
            # Come back to this later, I am not sure if this is necessary
            # That string maybe static (i.e. always the same)
            # https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/NamingConvention_FASTQ-files-swBS.htm#
            try: new_ext = "_{}{}".format(matched.group('lane'), new_ext)
            except IndexError: pass # Does not contain the named group lane

            filename = re.sub(regex, new_ext, filename)
            break # only rename once

    if not converted:
        raise NameError("""\n\tFatal: Failed to rename provided input '{}'!
        Cannot determine the extension of the user provided input file.
        Please rename the file list above before trying again.
        Here is example of acceptable input file extensions:
          sampleName.R1.fastq.gz      sampleName.R2.fastq.gz
          sampleName_R1_001.fastq.gz  sampleName_R1_001.fastq.gz
          sampleName_1.fastq.gz       sampleName_2.fastq.gz
        Please also check that your input files are gzipped?
        If they are not, please gzip them before proceeding again.
        """.format(filename, sys.argv[0])
        )

    return filename

## FROM: https://github.com/skchronicles/RNA-seek/blob/main/rna-seek
def _sym_safe_(input_data, target):
    """Creates re-named symlinks for each FastQ file provided
    as input. If a symlink already exists, it will not try to create a new symlink.
    If relative source PATH is provided, it will be converted to an absolute PATH.
    @param input_data <list[<str>]>:
        List of input files to symlink to target location
    @param target <str>:
        Target path to copy templates and required resources
    @return input_fastqs list[<str>]:
        List of renamed input FastQs
    """
    input_fastqs = [] # store renamed fastq file names
    for file in input_data:
        filename = os.path.basename(file)
        renamed = os.path.join(target, rename(filename))
        input_fastqs.append(renamed)

        if not os.path.exists(renamed):
            # Create a symlink if it does not already exist
            # Follow source symlinks to resolve any binding issues
            os.symlink(os.path.abspath(os.path.realpath(file)), renamed)

    return input_fastqs

def read_pairsfile(pairs_filepath):
    ## Could add more error-checking here; file access, header names,...
    if not os.path.isfile(pairs_filepath):
        raise NameError("""\n\tFatal: The pairs file was not found!
        This is the path that was given in the config: {}
        """.format(pairs_filepath, sys.argv[0])
        )
    df = pd.read_csv(pairs_filepath, header=0, sep='\t')
    mydict = dict(zip(df['Tumor'].tolist(), df['Normal'].tolist()))
    return mydict

configfile:"references_hg38.json"


######### PARSE CONFIG PARAMS #########
BASEDIR=os.path.realpath(config['input_params']['BASE_OUTDIR'])

input_fqdir=os.path.join(BASEDIR,"input_files","fastq")
fq_source=config['input_params']['FASTQ_SOURCE']
fqs_found=glob.glob(os.path.join(fq_source,'*.fastq.gz'))

input_bamdir=os.path.join(BASEDIR,"input_files","bam")
bam_source=os.path.join(config['input_params']['BAM_SOURCE'])
bams_found=glob.glob(os.path.join(bam_source,'*.bam'))

output_fqdir=os.path.join(BASEDIR,config['output_params']['FASTQ'])
output_bamdir=os.path.join(BASEDIR,config['output_params']['BAM'])
output_qcdir=os.path.join(BASEDIR,"QC")


name_symlinks=[]
if fqs_found:
    name_suffix=".R[1,2].fastq.gz"
    if not os.path.exists(input_fqdir):
        # print("making"+output_fqdir)
        os.makedirs(input_fqdir) 
        name_symlinks=_sym_safe_(fqs_found, input_fqdir)
    else:
        name_symlinks=glob.glob(os.path.join(input_fqdir,'*.fastq.gz'))
elif bams_found:
    name_suffix=".input.bam"
    if not os.path.exists(input_bamdir):
        os.makedirs(input_bamdir) 
    if (len(os.listdir(input_bamdir))==0):
        bam_symlinks=_sym_safe_(bams_found, input_bamdir)
    name_symlinks=glob.glob(os.path.join(input_bamdir,'*.input.bam'))
else:
    raise NameError("""\n\tFatal: No relevant files found in the BAM or FASTQ directory!
        FASTQ source path provided: {}
        BAM source path provided: {}
        Folders should contain files ending with '.fastq.gz' or '.bam' respectively.
        """.format(fq_source, bam_source, sys.argv[0])
    )

samples = set([re.sub(name_suffix,"",os.path.basename(fname)) for fname in name_symlinks]) ## Only returns paired fqs

pairs_file = config['input_params']['PAIRS_FILE']
if not pairs_file:
    pairs_dict=dict.fromkeys(samples)
else:
    pairs_dict = read_pairsfile(pairs_file)

pairs_ids=list(pairs_dict.keys())

output_germline_base=os.path.join(BASEDIR,"germline")
output_somatic_base=os.path.join(BASEDIR,"somatic")
output_somatic_snpindels=os.path.join(output_somatic_base,"SNP_Indels")
output_somatic_cnv=os.path.join(output_somatic_base,"CNV")

chroms = ["chr1","chr2","chr3","chr4","chr5","chr6","chr7","chr8","chr9","chr10","chr11","chr12","chr13","chr14","chr15","chr16","chr17","chr18","chr19","chr20","chr21","chr22","chrX","chrY","chrM"]
intervals_file=os.path.join(BASEDIR,"intervals.list")
if not os.path.isfile(intervals_file):
    with open(intervals_file, 'w') as f:
        f.write("\n".join(chroms))
        f.close

# caller_dict=config['output_params']['SOMATIC_VCF']
caller_list=[caller_name.lower() for caller_name in config['input_params']['VARIANT_CALLERS']]
caller_list=list(set(caller_list) & set(config['available_somatic_callers']))

if not caller_list:
    raise NameError("""\n\tFatal: Must define one or more variant caller!
        """.format(fq_source, input_bamdir, sys.argv[0])
    )

merge_outdir=config['output_params']['MERGED_SOMATIC_OUTDIR']
somatic_callers_dirs = [caller + "_out" for caller in list(caller_list)]

samples_for_caller_merge=[]
merge_callers_args=dict.fromkeys(pairs_ids)
merge_callers_rodlist=",".join(caller_list)
if (len(caller_list) > 1):
    merge_callers_args_list = [["--variant:{} {}/{}/{}.FINAL.vcf".format(re.sub("_out","",vc_out), os.path.join(output_somatic_snpindels, vc_out),"vcf",pair_id) for vc_out in somatic_callers_dirs] for pair_id in pairs_ids]
    merge_callers_args = dict(zip(pairs_ids, [" ".join(arglist) for arglist in merge_callers_args_list]))
    samples_for_caller_merge=pairs_ids
    somatic_callers_dirs=list(somatic_callers_dirs + [merge_outdir])

VCF2MAF_WRAPPER=config['scripts']['vcf2maf_wrapper']
SOBDetector_out=os.path.join(output_somatic_base,"ffpe_filter","sobdetector")
SOBDetector_JARFILE=os.path.join(SOBDetector_out, "jarfile","SOBDetector_v1.0.2.jar")

exome_targets_bed=config['input_params']['EXOME_TARGETS']

ffpe_caller_list=[]
ffpe_sample_list=[]
if 'FFPE_FILTER' in config['input_params']:
    if config['input_params']['FFPE_FILTER'].lower() in ['true','t','yes']:
        ffpe_caller_list=somatic_callers_dirs
        ffpe_sample_list=pairs_ids

config['input_params']['CNV_CALLING'] = "False"  ## Hardcoding CNV calling to always turn off for now
cnv_sample_list=[]
if 'CNV_CALLING' in config['input_params']:
    if config['input_params']['CNV_CALLING'].lower() in ['true','t','yes']:
        cnv_sample_list=pairs_ids    
    
# print(somatic_callers_dirs)
# print(samples_for_caller_merge)
# print(config['input_params']['FFPE_FILTER'].lower() )
# print(ffpe_caller_list)
# print(len(caller_list))
# # print(pairs_dict)
# print(merge_callers_args)
# exit()

#
# Set rule all
#

rule all:
    input:
        expand(os.path.join(input_bamdir,"{samples}.input.bam"), samples=samples),
        expand(os.path.join(output_bamdir,"final_bams","{samples}.bam"), samples=samples),
        # expand(os.path.join(output_bamdir,"preprocessing","{samples}.input.bai"), samples=samples),
        expand(os.path.join(output_germline_base,"VCF","{samples}.germline.vcf.gz"), samples=samples),

        # expand(os.path.join(output_somatic_snpindels,merge_outdir,"vcf","{samples}.FINAL.vcf"),samples=samples_for_caller_merge),
        expand(os.path.join(output_somatic_snpindels,merge_outdir,"vcf","{samples}.FINAL.norm.vcf"),samples=samples_for_caller_merge),
        expand(os.path.join(output_somatic_snpindels,merge_outdir,"maf","{samples}.maf"),samples=samples_for_caller_merge),
        # expand(os.path.join("{vc_outdir}","maf","{samples}.maf"), samples=pairs_ids, vc_outdir=somatic_callers),
        
        expand(os.path.join(output_somatic_snpindels,"{vc_outdir}","cohort_summary","all_somatic_variants.maf"), vc_outdir=somatic_callers_dirs),
        # expand(os.path.join(SOBDetector_out,"{vc_outdir}","cohort_summary","all_somatic_variants.maf"), samplespairs_ids, vc_outdir=somatic_callers),
        
        expand(os.path.join(SOBDetector_out,"{vc_outdir}","pass2","{samples}.artifact_filtered.vcf.gz"), samples=ffpe_sample_list, vc_outdir=ffpe_caller_list),
        expand(os.path.join(SOBDetector_out,"{vc_outdir}","cohort_summary","all_somatic_variants.maf"), vc_outdir=ffpe_caller_list),
        # expand(os.path.join(SOBDetector_out,"{vc_outdir}","pass2","{samples}.sobdetect.vcf"), samplespairs_ids, vc_outdir=somatic_callers_dirs),
        expand(os.path.join(SOBDetector_out,"{vc_outdir}","metrics","all_metrics.txt"), vc_outdir=ffpe_caller_list),
        
        
        expand(os.path.join(output_somatic_cnv,"freec_out","pass2","{samples}.recal.bam_CNVs.p.value.txt"), samples=cnv_sample_list),
        
        expand(os.path.join(output_somatic_base,"qc","gatk_contamination","{samples}.contamination.table"), samples=samples),

        expand(os.path.join(output_fqdir,"{samples}.fastq.info.txt"), samples=samples),
        expand(os.path.join(output_qcdir,"FQscreen","{samples}.R2.trimmed_screen.txt"), samples=samples),
        expand(os.path.join(output_qcdir,"kraken","{samples}.trimmed.kraken_bacteria.krona.html"), samples=samples),
        expand(os.path.join(output_qcdir,"{samples}.recal_fastqc.zip"), samples=samples),
        expand(os.path.join(output_qcdir,"{samples}","genome_results.txt"), samples=samples),
        expand(os.path.join(output_qcdir,"{samples}.samtools_flagstat.txt"), samples=samples),
        os.path.join(output_qcdir,"raw_variants.het"), 
        os.path.join(output_qcdir,"raw_variants.variant_calling_detail_metrics"),
        
        expand(os.path.join(output_qcdir,"{samples}.germline.bcftools_stats.txt"), samples=samples),
        expand(os.path.join(output_qcdir,"{samples}.germline.eval.grp"), samples=samples),
        expand(os.path.join(output_qcdir,"{samples}.germline.snpeff.ann.html"), samples=samples),

        # expand(os.path.join(output_somatic_base,"qc","qualimap","{samples}.qualimapReport","genome_results.txt"), samples=samples),
        # os.path.join("merged_somatic_variants","maf","merged_oncoplot.pdf"),
        # os.path.join("mutect_out","maf","mutect_oncoplot.pdf"),
        # os.path.join("mutect2_out","maf","mutect2_oncoplot.pdf"),
        # os.path.join("strelka_out","maf","strelka_oncoplot.pdf"),
        # expand(os.path.join("superfreq","vcfs","{samples}.allRaw.vcf"), samples),
        # expand(os.path.join("pyclone","{samples}","config.yaml"), samples),
        # expand("HLA/{samplesb}/hla/R1_bestguess_G.txt", samplesb=samplesb),

rule trimmomatic:
    input:  r1=os.path.join(input_fqdir, "{samples}.R1.fastq.gz"),
            r2=os.path.join(input_fqdir, "{samples}.R2.fastq.gz")
    output: one=temp(os.path.join(output_fqdir,"{samples}.R1.trimmed.fastq.gz")),
            two=temp(os.path.join(output_fqdir,"{samples}.R1.trimmed.unpair.fastq.gz")),
            three=temp(os.path.join(output_fqdir,"{samples}.R2.trimmed.fastq.gz")),
            four=temp(os.path.join(output_fqdir,"{samples}.R2.trimmed.unpair.fastq.gz")),
            err=os.path.join(output_fqdir,"{samples}_run_trimmomatic.err")
    params: adapterfile=config['references']['trimmomatic.adapters'],ver=config['tools']['trimmomatic']['version'],rname="pl:trimmomatic"
    # threads: 32
    shell:  """
            module load trimmomatic/{params.ver};
            myoutdir="$(dirname {output.one})"
            if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi
            
            trimmomatic PE -threads $((SLURM_CPUS_PER_TASK-1)) -phred33 {input.r1} {input.r2} {output.one} {output.two} {output.three} {output.four} ILLUMINACLIP:{params.adapterfile}:3:30:10 LEADING:10 TRAILING:10 SLIDINGWINDOW:4:20 MINLEN:20 2> {output.err}
            
            """
#trimmomatic PE -threads $((CPUS_PER_TASK-1)) -phred33 {input[0]} {input[1]} {output.one} {output.two} {output.three} {output.four} ILLUMINACLIP:{params.adapterfile}:3:30:10 LEADING:10 TRAILING:10 SLIDINGWINDOW:4:20 MINLEN:20 2> {output.err}

rule bwa_mem:
    input:  os.path.join(output_fqdir,"{samples}.R1.trimmed.fastq.gz"),
            os.path.join(output_fqdir,"{samples}.R2.trimmed.fastq.gz")
    output: temp(os.path.join(output_bamdir,"preprocessing","{samples}.raw_map.bam"))
    params: genome=config['references']['GENOME'],sample = "{samples}",ver_samtools=config['tools']['samtools']['version'],ver_bwa=config['tools']['bwa']['version'],rname="pl:bwamem"
    # threads: 32
    shell:  """
            module load samtools/{params.ver_samtools}
            module load bwa/{params.ver_bwa}
            myoutdir="$(dirname {output})"
            if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi
            bwa mem -M -R \'@RG\\tID:{params.sample}\\tSM:{params.sample}\\tPL:illumina\\tLB:{params.sample}\\tPU:{params.sample}\\tCN:hgsc\\tDS:wes\' -t $((SLURM_CPUS_PER_TASK-1)) {params.genome} {input} | /usr/local/apps/samblaster/0.1.25/bin/samblaster -M | samtools sort -@12 -m 4G - -o {output}
            """

rule raw_index:
      input:  bam=os.path.join(output_bamdir,"preprocessing","{samples}.raw_map.bam")
      output: bai=temp(os.path.join(output_bamdir,"preprocessing","{samples}.raw_map.bai")),
      params: ver_samtools=config['tools']['samtools']['version'],rname="raw_index"
      shell:  """
              module load samtools/{params.ver_samtools}
              samtools index -@ 2 {input.bam} {output.bai}
              """
rule realign:
      input:  bam=os.path.join(output_bamdir,"preprocessing","{samples}.raw_map.bam"),
              bai=os.path.join(output_bamdir,"preprocessing","{samples}.raw_map.bai"),
      output: bam=temp(os.path.join(output_bamdir,"preprocessing","{samples}.realign.bam")),
              int=temp(os.path.join(output_bamdir,"preprocessing","{samples}.intervals")),
      params: genome=config['references']['GENOME'],knowns=config['references']['KNOWNINDELS'],ver_gatk=config['tools']['gatk3']['version'],rname="realign"
      shell:  """
              module load GATK/{params.ver_gatk}
              java -Xmx48g -jar $GATK_JAR -T RealignerTargetCreator -I {input.bam} -R {params.genome} -o {output.int} {params.knowns}
              java -Xmx48g -jar $GATK_JAR -T IndelRealigner -R {params.genome} -I {input.bam} {params.knowns} --use_jdk_inflater --use_jdk_deflater -targetIntervals {output.int} -o {output.bam}
              """

rule gatk_recal:
      input:  os.path.join(output_bamdir,"preprocessing","{samples}.realign.bam")
      output: bam=os.path.join(input_bamdir,"{samples}.input.bam"),
              re=temp(os.path.join(output_bamdir,"preprocessing","{samples}_recal_data.grp"))
      params: genome=config['references']['GENOME'],knowns=config['references']['KNOWNRECAL'],ver_gatk=config['tools']['gatk4']['version'],rname="recal"
      threads: 24
      shell:  """
              module load GATK/{params.ver_gatk}
              gatk --java-options '-Xmx48g' BaseRecalibrator --input {input} --reference {params.genome} {params.knowns} --output {output.re}
              gatk --java-options '-Xmx48g' ApplyBQSR --reference {params.genome} --input {input} --bqsr-recal-file {output.re} --output {output.bam} --use-jdk-inflater --use-jdk-deflater
              """

rule bam_check:
      input:  bam=os.path.join(input_bamdir,"{samples}.input.bam")
      output: bam=os.path.join(output_bamdir,"final_bams","{samples}.bam"),
              bai=os.path.join(output_bamdir,"final_bams","{samples}.bai"),
              bai2=os.path.join(output_bamdir,"final_bams","{samples}.bam.bai"),
      params: ver_samtools=config['tools']['samtools']['version'],
              ver_gatk=config['tools']['gatk4']['version'],
              rname="bam_check"
      shell:  """
              module load samtools/{params.ver_samtools}
              module load GATK/{params.ver_gatk}
              
              sample={wildcards.samples}
              ID=$sample
              PL="ILLUMINA"  ### Should be exposed as a config param
              LB="na"        ### Should be exposed as a config param (?)
              
              ##Check if there is no header or any of the info
              HEADER=`samtools view -H {input.bam} | grep ^@RG`
              if [[ "$HEADER" != "" ]]; then
                  t=(${{HEADER//\t/ }})
                  echo ${{t[1]}}
                  ID=`printf '%s\n' "${{t[@]}}" | grep -P '^ID' | cut -d":" -f2` #(${{t[1]//:/ }})
                  PL=`printf '%s\n' "${{t[@]}}" | grep -P '^PL' | cut -d":" -f2` #(${{t[3]//:/ }})
                  LB=`printf '%s\n' "${{t[@]}}" | grep -P '^LB' | cut -d":" -f2` #(${{t[2]//:/ }})
                  if [[ "$ID" == "$sample" ]]; then
                      echo "The header of the BAM file is correct"
                  else
                      ID=$sample
                  fi
              fi
              gatk AddOrReplaceReadGroups --INPUT {input.bam} --OUTPUT {output.bam} --RGID ${{ID}} --RGLB ${{LB}} --RGPL ${{PL}} --RGSM ${{ID}} --RGPU na
              
              samtools index -@ 2 {output.bam} {output.bai}
              cp {output.bai} {output.bai2}
              """
    
rule split_bam_by_chrom:
      input:  bam=os.path.join(output_bamdir,"final_bams","{samples}.bam"),
              bai=os.path.join(output_bamdir,"final_bams","{samples}.bam.bai"),
      output: split_bam=os.path.join(output_bamdir,"chrom_split","{samples}.{chroms}.split.bam"),
              split_bam_idx=os.path.join(output_bamdir,"chrom_split","{samples}.{chroms}.split.bai")
      params: ver_samtools=config['tools']['samtools']['version'],rname="bam_split"
      shell:  """
              if [ ! -d "$(dirname {output.split_bam})" ]; then
                mkdir -p "$(dirname {output.split_bam})"
              fi
              module load samtools/{params.ver_samtools}
              samtools view -b -o {output.split_bam} -@ $((SLURM_CPUS_PER_TASK-1)) {input.bam} {wildcards.chroms}
              samtools index -@ 2 {output.split_bam} {output.split_bam_idx}
              cp {output.split_bam_idx} {output.split_bam}.bai
              """

rule mutect2_single:
    input: tumor=os.path.join(output_bamdir,"chrom_split","{samples}.{chroms}.split.bam")
    output: vcf=os.path.join(output_somatic_snpindels,"mutect2_out","chrom_split","{samples}.{chroms}.vcf"),
            # vcfgz=os.path.join(output_somatic_snpindels,"mutect2_out","chrom_split","{samples}.{chroms}.vcf.gz"),
            read_orientation_file=os.path.join(output_somatic_snpindels,"mutect2_out","chrom_split","{samples}.{chroms}.f1r2.tar.gz"),
            statsfiles=os.path.join(output_somatic_snpindels,"mutect2_out","chrom_split","{samples}.{chroms}.vcf.stats")
    params: tumorsample="{samples}",
            genome = config['references']['GENOME'],
            pon=config['references']['PON'],
            germsource=config['references']['GNOMAD'],
            ver_gatk=config['tools']['gatk4']['version'],
            # ver_bcftools=config['tools']['bcftools']['version'],
            rname="mutect2"
    threads: 2
    shell: """
           if [ ! -d "$(dirname {output.vcf})" ]; then
               mkdir -p "$(dirname {output.vcf})"
           fi
           module load GATK/{params.ver_gatk}
           gatk Mutect2 -R {params.genome} -I {input.tumor} --panel-of-normals {params.pon} --germline-resource {params.germsource} -L {wildcards.chroms} -O {output.vcf} --f1r2-tar-gz {output.read_orientation_file} --independent-mates
           """
           # module load bcftools/{params.ver_bcftools}
           # bgzip --threads $((SLURM_CPUS_PER_TASK - 1)) -c "{output.vcf}" > "{output.vcfgz}"
           # bcftools index -t {output.vcfgz}

rule LearnReadOrientationModel:
    input: vcf=expand(os.path.join(output_somatic_snpindels,"mutect2_out","chrom_split","{{samples}}.{chroms}.vcf"), chroms=chroms),
           read_orientation_file=expand(os.path.join(output_somatic_snpindels,"mutect2_out","chrom_split","{{samples}}.{chroms}.f1r2.tar.gz"), chroms=chroms)
    output: model=os.path.join(output_somatic_snpindels,"mutect2_out","read_orientation_data","{samples}.read-orientation-model.tar.gz")
    params: genome = config['references']['GENOME'],ver_gatk=config['tools']['gatk4']['version'],rname="LearnReadOrientationModel"
    shell: """
           module load GATK/{params.ver_gatk}
           input_str="--input $(echo "{input.read_orientation_file}" | sed -e 's/ / --input /g')"
           
           gatk LearnReadOrientationModel --output {output.model} $input_str
           """

###Merge MuTect2 VCFs

# rule gatk_merge_mutect2_chrom:
#     input: vcf=expand(os.path.join(output_somatic_snpindels,"mutect2_out","chrom_split","{{samples}}.{chroms}.vcf"), chroms=chroms),
#     output: vcf=os.path.join(output_somatic_snpindels,"mutect2_out","vcf","{samples}.collected.vcf"),
#     params: normalsample=lambda w: [pairs_dict[w.samples]],tumorsample="{samples}",genome = config['references']['GENOME'],ver_gatk=config['tools']['gatk3']['version'],rname="merge"
#     shell: """
#            module load GATK/{params.ver_gatk}
#            input_str="--variant $(echo "{input.vcf}" | sed -e 's/ / --variant /g')"
#            GATK -m 48G CombineVariants -R {params.genome} --filteredrecordsmergetype KEEP_UNCONDITIONAL --assumeIdenticalSamples -o {output.vcf} $input_str
#            """
        
rule pileup:
    input: tumor=os.path.join(output_bamdir,"final_bams","{samples}.bam"),
           bai=os.path.join(output_bamdir,"final_bams","{samples}.bai"),
           intervals=intervals_file
    output: pileup=temp(os.path.join(output_somatic_snpindels,"mutect2_out","pileup_summaries","{samples}.pileup.table")),
    params: genome=config['references']['GENOME'],germsource=config['references']['1000GSNP'],ver_gatk=config['tools']['gatk4']['version'],chroms=chroms, rname="pileup"
    shell: """
           module load GATK/{params.ver_gatk}
           gatk --java-options "-Xmx10g -Djava.io.tmpdir=/lscratch/$SLURM_JOBID" GetPileupSummaries -R {params.genome} -I {input.tumor} -V {params.germsource} -L {input.intervals} -O {output.pileup}
           """
           
rule contamination:
    input: pileup=os.path.join(output_somatic_snpindels,"mutect2_out","pileup_summaries","{samples}.pileup.table"),
    output: tumor_summary=os.path.join(output_somatic_base,"qc","gatk_contamination","{samples}.contamination.table"),
    params: genome=config['references']['GENOME'],germsource=config['references']['1000GSNP'],ver_gatk=config['tools']['gatk4']['version'],chroms=chroms, rname="pileup"
    shell: """
           module load GATK/{params.ver_gatk}
           gatk CalculateContamination -I {input.pileup} -O {output.tumor_summary}
           """

# rule pileup_normal:
#     input: normal = lambda w: [os.path.join(output_bamdir, pairs_dict[w.samples] + ".bam")],
#     output: summary=os.path.join(output_somatic_snpindels,"mutect2_out","pileup_summaries","{samples}_normal.pileup.table")
#     params: genome=config['references']['GENOME'],germsource=config['references']['1000GSNP'],ver_gatk=config['tools']['gatk4']['version'],rname="pileup"
#     shell: """
#            module load GATK/{params.ver_gatk}
#            gatk --java-options '-Xmx48g' GetPileupSummaries -I {input.normal} -V {params.germsource} -L {params.germsource} -O {output.summary}
#            """
# 
# rule contamination:
#     input: tumor=os.path.join(output_somatic_snpindels,"mutect2_out","pileup_summaries","{samples}_tumor.pileup.table"),
#     output: tumor_summary=os.path.join(output_somatic_base,"qc","gatk_contamination","{samples}.tumor.contamination.table"),
#     params: tumorsample="{samples}",genome=config['references']['GENOME'],ver_gatk=config['tools']['gatk4']['version'],rname="contamination"
#     shell: """
#            module load GATK/{params.ver_gatk}
#            gatk CalculateContamination -I {input.tumor} -O {output.tumor_summary}
           # """

rule mutect2_filter_single:
    input: vcf=os.path.join(output_somatic_snpindels,"mutect2_out","vcf","{samples}.collected.vcf"),
           summary=os.path.join(output_somatic_base,"qc","gatk_contamination","{samples}.contamination.table"),
           model=os.path.join(output_somatic_snpindels,"mutect2_out","read_orientation_data","{samples}.read-orientation-model.tar.gz"),
           statsfiles=expand(os.path.join(output_somatic_snpindels,"mutect2_out","chrom_split","{{samples}}.{chroms}.vcf.stats"), chroms=chroms)
    output: marked_vcf=os.path.join(output_somatic_snpindels,"mutect2_out","vcf","{samples}.filtered.vcf"),
            final=os.path.join(output_somatic_snpindels,"mutect2_out","vcf","{samples}.FINAL.vcf"),
            norm=os.path.join(output_somatic_snpindels,"mutect2_out","vcf","{samples}.FINAL.norm.vcf"),
    params: tumorsample="{samples}",
            genome=config['references']['GENOME'],
            ver_gatk=config['tools']['gatk4']['version'],
            ver_bcftools=config['tools']['bcftools']['version'],
            rname="mutect2_filter"
    shell: """
           module load GATK/{params.ver_gatk}
           
           statfiles="--stats $(echo "{input.statsfiles}" | sed -e 's/ / --stats /g')"
           gatk MergeMutectStats $statfiles -O {output.final}.stats
           gatk FilterMutectCalls -R {params.genome} -V {input.vcf} --ob-priors {input.model} --contamination-table {input.summary} -O {output.marked_vcf} --stats {output.final}.stats
           gatk SelectVariants -R {params.genome} --variant {output.marked_vcf} --exclude-filtered --output {output.final}
           
           module load bcftools/{params.ver_bcftools}
           ## (At least) VarScan outputs ambiguous IUPAC bases/codes sometimes; the piped awk one-liner sets them to N
           ## From: https://github.com/fpbarthel/GLASS/issues/23
           bcftools sort -T /lscratch/$SLURM_JOB_ID "{output.final}" | \
               bcftools norm --threads $((SLURM_CPUS_PER_TASK - 1)) --check-ref s -f {params.genome} -O v | \
               awk '{{gsub(/\y[W|K|Y|R|S|M]\y/,"N",$4); OFS = "\t"; print}}' | sed '/^$/d' > {output.norm}
           """

rule mutect_single:
       input:  tumor=os.path.join(output_bamdir,"chrom_split","{samples}.{chroms}.split.bam"),
       output: vcf=os.path.join(output_somatic_snpindels,"mutect_out","chrom_split","{samples}.{chroms}.vcf"),
               # vcfgz=temp(os.path.join(output_somatic_snpindels,"mutect_out","chrom_split","{samples}.{chroms}.vcf.gz")),
               stats=os.path.join(output_somatic_snpindels,"mutect_out","chrom_split","{samples}.{chroms}.stats.out"),
               # final=os.path.join(output_somatic_snpindels,"mutect_out","vcf","{samples}.FINAL.vcf"),
       params: genome=config['references']['GENOME'],
               pon=config['references']['PON'],
               cosmic=config['references']['COSMIC'],
               dbsnp=config['references']['DBSNP'],
               ver_mutect=config['tools']['mutect']['version'],
               # ver_bcftools=config['tools']['bcftools']['version'],
               rname="mutect"
       shell:  """
               myoutdir="$(dirname {output.vcf})"
               if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi
               
               module load muTect/{params.ver_mutect}
               muTect --analysis_type MuTect --reference_sequence {params.genome} --normal_panel {params.pon} --vcf {output.vcf} --cosmic {params.cosmic} --dbsnp {params.dbsnp} -L {wildcards.chroms} --disable_auto_index_creation_and_locking_when_reading_rods --input_file:tumor {input.tumor} --out {output.stats} -rf BadCigar
               """

rule mutect_filter_single:
    input: vcf=os.path.join(output_somatic_snpindels,"mutect_out","vcf","{samples}.collected.vcf"),
    output: final=os.path.join(output_somatic_snpindels,"mutect_out","vcf","{samples}.FINAL.vcf"),
            norm=os.path.join(output_somatic_snpindels,"mutect_out","vcf","{samples}.FINAL.norm.vcf"),
    params: tumorsample="{samples}",
            genome=config['references']['GENOME'],
            ver_gatk=config['tools']['gatk4']['version'],
            ver_bcftools=config['tools']['bcftools']['version'],
            rname="mutect_filter"
    shell: """
           module load GATK/{params.ver_gatk}
           gatk SelectVariants -R {params.genome} --variant {input.vcf} --exclude-filtered --output {output.final}
           
           module load bcftools/{params.ver_bcftools}
           ## (At least) VarScan outputs ambiguous IUPAC bases/codes sometimes; the piped awk one-liner sets them to N
           ## From: https://github.com/fpbarthel/GLASS/issues/23
           bcftools sort -T /lscratch/$SLURM_JOB_ID "{output.final}" | \
               bcftools norm --threads $((SLURM_CPUS_PER_TASK - 1)) --check-ref s -f {params.genome} -O v | \
               awk '{{gsub(/\y[W|K|Y|R|S|M]\y/,"N",$4); OFS = "\t"; print}}' | sed '/^$/d' > {output.norm}
           """

rule vardict_single:
       input:  tumor=os.path.join(output_bamdir,"chrom_split","{samples}.{chroms}.split.bam"),
       output: vcf=os.path.join(output_somatic_snpindels,"vardict_out","chrom_split","{samples}.{chroms}.vcf"),
               # vcfgz=temp(os.path.join(output_somatic_snpindels,"vardict_out","chrom_split","{samples}.{chroms}.vcf.gz")),
       params: genome=config['references']['GENOME'],
               targets=exome_targets_bed,
               pon=config['references']['PON'],
               ver_bcftools=config['tools']['bcftools']['version'],
               rname="vardict"
       shell:  """
               myoutdir="$(dirname {output.vcf})"
               if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi
               module load R/3.6.1
               module load samtools/1.8
               #module load java/1.8.0_92
               
               /data/CCBR_Pipeliner/db/PipeDB/bin/VarDictJava/build/install/VarDict/bin/VarDict -G {params.genome} -f 0.05 -x 500 --nosv -b {input.tumor} -t -Q 20 -c 1 -S 2 -E 3 {params.targets} | \
               /data/CCBR_Pipeliner/db/PipeDB/bin/VarDictJava/build/install/VarDict/bin/teststrandbias.R | \
               /data/CCBR_Pipeliner/db/PipeDB/bin/VarDictJava/build/install/VarDict/bin/var2vcf_valid.pl -N {wildcards.samples} -Q 20 -d 10 -v 6 -S -E -f 0.05 > {output.vcf}
               """

rule vardict_filter_single:
       input:  vcf=os.path.join(output_somatic_snpindels,"vardict_out","vcf","{samples}.collected.vcf"),
       output: final=os.path.join(output_somatic_snpindels,"vardict_out","vcf","{samples}.FINAL.vcf"),
               norm=os.path.join(output_somatic_snpindels,"vardict_out","vcf","{samples}.FINAL.norm.vcf"),
               # filtered=temp(os.path.join(output_somatic_snpindels,"vardict_out","vcf","{samples}.filtered.vcf")),
       params: tumorsample="{samples}",
               genome=config['references']['GENOME'],
               targets=exome_targets_bed,pon=config['references']['PON'],
               ver_gatk=config['tools']['gatk4']['version'],
               ver_bcftools=config['tools']['bcftools']['version'],
               rname="vardict_filter"
       shell:  """
               module load GATK/{params.ver_gatk}
               gatk SelectVariants -R {params.genome} --variant {input.vcf} --discordance {params.pon} --exclude-filtered --output {output.final}
               
               module load bcftools/{params.ver_bcftools}
               ## (At least) VarScan outputs ambiguous IUPAC bases/codes sometimes; the piped awk one-liner sets them to N
               ## From: https://github.com/fpbarthel/GLASS/issues/23
               bcftools sort -T /lscratch/$SLURM_JOB_ID "{output.final}" | \
                   bcftools norm --threads $((SLURM_CPUS_PER_TASK - 1)) --check-ref s -f {params.genome} -O v | \
                   awk '{{gsub(/\y[W|K|Y|R|S|M]\y/,"N",$4); OFS = "\t"; print}}' | sed '/^$/d' > {output.norm}
               """

rule varscan_single:
       input:  tumor=os.path.join(output_bamdir,"chrom_split","{samples}.{chroms}.split.bam"),
       output: vcf=os.path.join(output_somatic_snpindels,"varscan_out","chrom_split","{samples}.{chroms}.vcf"),
       params: genome=config['references']['GENOME'],
               ver_varscan=config['tools']['varscan']['version'],
               ver_bcftools=config['tools']['bcftools']['version'],
               rname="varscan"
       shell:  """
               if [ ! -d "$(dirname {output.vcf})" ]; then
                   mkdir -p "$(dirname {output.vcf})"
               fi
               module load VarScan/{params.ver_varscan}
               
               varscan_opts="--strand-filter 0 --min-var-freq 0.01 --output-vcf 1 --variants 1"
               
               pileup_cmd="samtools mpileup -d 100000 -q 15 -Q 15 -f {params.genome} {input.tumor}"
               varscan_cmd="varscan mpileup2cns <($pileup_cmd) $varscan_opts"
               
               #full_cmd="$varscan_cmd | bcftools view -U > {output.vcf}"
               #eval "$full_cmd"
               
               eval "$varscan_cmd > {output.vcf}.gz"
               eval "bcftools view -U {output.vcf}.gz > {output.vcf}"
               
               """

rule varscan_filter_single:
    input: vcf=os.path.join(output_somatic_snpindels,"varscan_out","vcf","{samples}.collected.vcf"),
    output: filtered=temp(os.path.join(output_somatic_snpindels,"varscan_out","vcf","{samples}.filtered.vcf")),
            filtered1=temp(os.path.join(output_somatic_snpindels,"varscan_out","vcf","{samples}.filtered.1.vcf")),
            samplesfile=temp(os.path.join(output_somatic_snpindels,"varscan_out","vcf","{samples}.FINAL.vcf.samples")),
            final=os.path.join(output_somatic_snpindels,"varscan_out","vcf","{samples}.FINAL.vcf"),
            norm=os.path.join(output_somatic_snpindels,"varscan_out","vcf","{samples}.FINAL.norm.vcf"),
    params: tumorsample="{samples}",genome=config['references']['GENOME'],
            pon=config['references']['PON'],
            basedir=BASEDIR,
            ver_gatk=config['tools']['gatk4']['version'],
            ver_varscan=config['tools']['varscan']['version'],
            ver_bcftools=config['tools']['bcftools']['version'],
            rname="varscan_filter"
    shell: """
           module load VarScan/{params.ver_varscan}
           varscan filter {input.vcf} {config[tools][varscan][filter_settings]} > {output.filtered1}
           
           module load GATK/{params.ver_gatk}
           gatk SelectVariants -R {params.genome} --variant {output.filtered1} --discordance {params.pon} --exclude-filtered --output {output.filtered}
           samplesFile="{output.samplesfile}"
           echo -e "TUMOR\t{params.tumorsample}\n" > "{output.samplesfile}"
           
           module load bcftools/{params.ver_bcftools}
           bcftools reheader -o "{output.final}" -s "{output.samplesfile}" "{output.filtered}"
           ## (At least) VarScan outputs ambiguous IUPAC bases/codes sometimes; the piped awk one-liner sets them to N
           ## From: https://github.com/fpbarthel/GLASS/issues/23
           bcftools sort -T /lscratch/$SLURM_JOB_ID "{output.final}" | \
            bcftools norm --threads $((SLURM_CPUS_PER_TASK - 1)) --check-ref s -f {params.genome} -O v | \
            awk '{{gsub(/\y[W|K|Y|R|S|M]\y/,"N",$4); OFS = "\t"; print}}' | sed '/^$/d' > {output.norm}
           """
           
# rule index_vcfs_somatic:
#     input: vcf=os.path.join(output_somatic_snpindels,"{vc_out}","chrom_split","{samples}.{chroms}.vcf"),
#     output: vcf=temp(os.path.join(output_somatic_snpindels,"{vc_out}","chrom_split","{samples}.{chroms}.vcf.gz")),
#     params: ver_bcftools=config['tools']['bcftools']['version'],rname="merge"
#     shell: """
#            module load bcftools/{params.ver_bcftools}
#            bgzip --threads $((SLURM_CPUS_PER_TASK - 1)) -c "{input.vcf}" > "{output.vcf}"
#            bcftools index -t {output.vcf}
#            """

# rule somatic_merge_chrom_bcftools:
#     input: vcf=expand(os.path.join(output_somatic_snpindels,"{{vc_out}}","chrom_split","{{samples}}.{chroms}.vcf.gz"), chroms=chroms),
#     output: vcf=os.path.join(output_somatic_snpindels,"{vc_out}","vcf","{samples}.collected.vcf"),
#     params: tumorsample="{samples}",genome = config['references']['GENOME'],ver_bcftools=config['tools']['bcftools']['version'],rname="merge_chrom"
#     shell: """
#            module load bcftools/{params.ver_bcftools}
#            ## (At least) VarScan outputs ambiguous IUPAC bases/codes sometimes; the piped awk one-liner sets them to N
#            ## From: https://github.com/fpbarthel/GLASS/issues/23
#            bcftools concat --threads $((SLURM_CPUS_PER_TASK - 1)) {input.vcf} | \
#             bcftools sort -T /lscratch/$SLURM_JOB_ID | \
#             bcftools norm --threads $((SLURM_CPUS_PER_TASK - 1)) --check-ref s -f {params.genome} -O v | \
#             awk '{{gsub(/\y[W|K|Y|R|S|M]\y/,"N",$4); OFS = "\t"; print}}' | sed '/^$/d' > {output.vcf}
#            """

rule somatic_merge_chrom:
    input: vcf=expand(os.path.join(output_somatic_snpindels,"{{vc_out}}","chrom_split","{{samples}}.{chroms}.vcf"), chroms=chroms),
    output: vcf=os.path.join(output_somatic_snpindels,"{vc_out}","vcf","{samples}.collected.vcf"),
    params: tumorsample="{samples}",genome = config['references']['GENOME'],genomedict = config['references']['GENOMEDICT'],ver_gatk=config['tools']['gatk4']['version'],rname="merge"
    shell: """
           module load GATK/{params.ver_gatk}
           input_str="-I $(echo "{input.vcf}" | sed -e 's/ / -I /g')"
           gatk --java-options "-Xmx30g" MergeVcfs -O "{output.vcf}" -D {params.genomedict} $input_str
           """


# rule somatic_merge_chrom:
#     input: vcf=expand(os.path.join(output_somatic_snpindels,"{{vc_out}}","chrom_split","{{samples}}.{chroms}.vcf"), chroms=chroms),
#     output: vcf=os.path.join(output_somatic_snpindels,"{vc_out}","vcf","{samples}.collected.vcf"),
#     params: tumorsample="{samples}",genome = config['references']['GENOME'],ver_gatk=config['tools']['gatk3']['version'],rname="merge"
#     shell: """
#            module load GATK/{params.ver_gatk}
#            input_str="--variant $(echo "{input.vcf}" | sed -e 's/ / --variant /g')"
#            GATK -m 48G CombineVariants -R {params.genome} --filteredrecordsmergetype KEEP_UNCONDITIONAL --assumeIdenticalSamples -o {output.vcf} $input_str
#            """


               
# rule normalize_indels:
#     input: vcf=os.path.join(output_somatic_snpindels,"{vc_out}","vcf","{samples}.FINAL.vcf"),
#     output: vcf=os.path.join(output_somatic_snpindels,"{vc_out}","vcf","{samples}.FINAL.norm.vcf"),
#     params: tumorsample="{samples}",genome = config['references']['GENOME'],ver_bcftools=config['tools']['bcftools']['version'],rname="merge_chrom"
#     shell: """
#            module load bcftools/{params.ver_bcftools}
#            ## (At least) VarScan outputs ambiguous IUPAC bases/codes sometimes; the piped awk one-liner sets them to N
#            ## From: https://github.com/fpbarthel/GLASS/issues/23
#            bcftools sort -T /lscratch/$SLURM_JOB_ID {input.vcf} | \
#             bcftools norm --threads $((SLURM_CPUS_PER_TASK - 1)) --check-ref s -f {params.genome} -O v | \
#             awk '{{gsub(/\y[W|K|Y|R|S|M]\y/,"N",$4); OFS = "\t"; print}}' | sed '/^$/d' > {output.vcf}
#            """
           
rule somatic_merge_callers:
    # input: vcf=expand(os.path.join(output_somatic_snpindels,"{vc_outdir}_out","vcf","{{samples}}.FINAL.vcf"), vc_outdir=caller_list)
    # output: mergedvcf=os.path.join(output_somatic_snpindels,"merged_somatic_variants","vcf","{samples}.FINAL.vcf"),
    input: vcf=expand(os.path.join(output_somatic_snpindels,"{vc_outdir}_out","vcf","{{samples}}.FINAL.norm.vcf"), vc_outdir=caller_list)
    output: mergedvcf=os.path.join(output_somatic_snpindels,"merged_somatic_variants","vcf","{samples}.FINAL.norm.vcf"),
    params: genome=config['references']['GENOME'],rodprioritylist=merge_callers_rodlist, variantsargs=lambda w: [merge_callers_args[w.samples]],ver_gatk=config['tools']['gatk3']['version'], rname="MergeSomaticCallers"
    shell: """
           if [ ! -d "$(dirname {output.mergedvcf})" ]; then
             mkdir -p "$(dirname {output.mergedvcf})"
           fi
           module load GATK/{params.ver_gatk}
           input_str="--variant $(echo "{input.vcf}" | sed -e 's/ / --variant /g')"
           nthread="$((SLURM_CPUS_PER_TASK-1))"
           java -Xmx60g -Djava.io.tmpdir=/lscratch/$SLURM_JOBID -jar $GATK_JAR -T CombineVariants -R {params.genome} -nt $nthread --filteredrecordsmergetype KEEP_IF_ANY_UNFILTERED --genotypemergeoption PRIORITIZE --rod_priority_list {params.rodprioritylist} --minimumN 1 -o {output.mergedvcf} {params.variantsargs}
           """
           
rule somatic_mafs:
  # input: filtered_vcf=os.path.join(output_somatic_snpindels,"{vc_outdir}","vcf","{samples}.FINAL.vcf"),
  input: filtered_vcf=os.path.join(output_somatic_snpindels,"{vc_outdir}","vcf","{samples}.FINAL.norm.vcf"),
         vcf2maf_script=VCF2MAF_WRAPPER
  output: maf=os.path.join(output_somatic_snpindels,"{vc_outdir}","maf","{samples}.maf")
  params: tumorsample="{samples}",genome=config['references']['MAF_GENOME'],filtervcf=config['references']['MAF_FILTERVCF'],rname="pl:vcf2maf"
  shell:
    """
    echo "Converting to MAF..."
    bash {input.vcf2maf_script} --vcf {input.filtered_vcf} --maf {output.maf} --tid {params.tumorsample} --genome {params.genome} --threads "$((SLURM_CPUS_PER_TASK-1))" --info "set"
    echo "Done converting to MAF..."
    date
    """
  
rule collect_cohort_mafs:
  input: mafs=expand(os.path.join(output_somatic_snpindels,"{{vc_outdir}}","maf","{samples}"+".maf"), samples=samples_for_caller_merge)
  output: maf=os.path.join(output_somatic_snpindels,"{vc_outdir}","cohort_summary","all_somatic_variants.maf")
  params: rname="combine_maf"
  shell:"""    
    date
    echo "Combining MAFs..."
    awk 'FNR==1 && NR!=1 {{ while (/^#/||/^Hugo_Symbol/) getline; }} 1 {{print}}' {input.mafs} > {output.maf}
    echo "Done..."
    date
  """
  

rule sobdetect_get:
    input: 
    output: SOBDetector_jar=SOBDetector_JARFILE
    params: rname="get_sobdetector"
    shell:
      """
      wget https://github.com/mikdio/SOBDetector/releases/download/v1.0.2/SOBDetector_v1.0.2.jar -O {output.SOBDetector_jar};
      """
    
    
rule sobdetect_pass1:
    # input: vcf=os.path.join(output_somatic_snpindels,"{vc_outdir}","vcf","{samples}.FINAL.vcf"),
    input: vcf=os.path.join(output_somatic_snpindels,"{vc_outdir}","vcf","{samples}.FINAL.norm.vcf"),
           bam=os.path.join(output_bamdir,"final_bams","{samples}.bam"),
           SOBDetector_jar=SOBDetector_JARFILE
    output: pass1_vcf=os.path.join(SOBDetector_out,"{vc_outdir}","pass1","{samples}.sobdetect.vcf"),
            pass1_info=os.path.join(SOBDetector_out,"{vc_outdir}","pass1","{samples}.info")
    params: chrom=chroms, rname="sobdetect1"
    shell:"""
        module load samtools;
        myoutdir="$(dirname {output.pass1_vcf})"
        if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi
        
        # touch $(echo "{input.bam}" | sed -e 's/.bam$/.bai/') ## SOBdetector sometimes complains about index being older than bam... Removing for now...
        
        java -jar {input.SOBDetector_jar} --input-type VCF --input-variants "{input.vcf}" --input-bam {input.bam} --output-variants {output.pass1_vcf} --only-passed false
        
        bcftools query -f '%INFO/numF1R2Alt\\t%INFO/numF2R1Alt\\t%INFO/numF1R2Ref\\t%INFO/numF2R1Ref\\t%INFO/numF1R2Other\\t%INFO/numF2R1Other\\t%INFO/SOB\\n' {output.pass1_vcf}| \
          awk '{{if ($1 != "."){{tum_alt=$1+$2; tum_depth=$1+$2+$3+$4+$5+$6; if (tum_depth==0){{tum_af=1}} else {{tum_af=tum_alt/tum_depth }}; print tum_alt,tum_depth,tum_af,$7}}}}' > {output.pass1_info} 
        """

    
rule sobdetect_cohort_params:
  input: info_files=expand(os.path.join(SOBDetector_out,"{{vc_outdir}}","pass1","{samples}.info"), samples=ffpe_sample_list)
  output: all_info_file=os.path.join(SOBDetector_out,"{vc_outdir}","pass1","all_samples.info"),
          params_file=os.path.join(SOBDetector_out,"{vc_outdir}","cohort_params.txt")
  params: rname="sobdetect_params"
  shell:
    """
    echo -e "#TUMOR.alt\\tTUMOR.depth\\tTUMOR.AF\\tSOB\\tFS\\tSOR\\tTLOD\\tReadPosRankSum" > {output.all_info_file}
    cat {input.info_files} >> {output.all_info_file}
    
    ## This is really stupid; I'm calculating mean and standard deviation in bash; a python one liner might be better?
    grep -v ^# {output.all_info_file} | \
      awk '{{ total1 += $1; ss1 += $1^2; total2 += $2; ss2 += $2^2; total3 += $3; ss3 += $3^2; total4 += $4; ss4 += $4^2 }} END {{ print total1/NR,total2/NR,total3/NR,total4/NR; print sqrt(ss1/NR-(total1/NR)^2),sqrt(ss2/NR-(total2/NR)^2),sqrt(ss3/NR-(total3/NR)^3),sqrt(ss4/NR-(total4/NR)^2) }}' > {output.params_file}
    """

    
rule sobdetect_pass2:
  # input: vcf=os.path.join(output_somatic_snpindels,"{vc_outdir}","vcf","{samples}.FINAL.vcf"),
  input: vcf=os.path.join(output_somatic_snpindels,"{vc_outdir}","vcf","{samples}.FINAL.norm.vcf"),
         bam=os.path.join(output_bamdir,"final_bams","{samples}.bam"),
         SOBDetector_jar=SOBDetector_JARFILE,
         params_file=os.path.join(SOBDetector_out,"{vc_outdir}","cohort_params.txt")
  output: pass2_vcf=os.path.join(SOBDetector_out,"{vc_outdir}","pass2","{samples}.sobdetect.vcf"),
          pass2_info=os.path.join(SOBDetector_out,"{vc_outdir}","pass2","{samples}.info"),
          filtered_vcf=os.path.join(SOBDetector_out,"{vc_outdir}","pass2","{samples}.artifact_filtered.vcf.gz")
  params: chrom=chroms,
          ver_bcftools=config['tools']['bcftools']['version'],
          rname="sobdetect2"
  shell:
    """
    module load samtools;
    date
    echo "Running SOBDetector..."
    myoutdir="$(dirname {output.pass2_vcf})"
    if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi
    
    java -jar {input.SOBDetector_jar} --input-type VCF --input-variants "{input.vcf}" --input-bam "{input.bam}" --output-variants "{output.pass2_vcf}" --only-passed true --standardization-parameters "{input.params_file}"
    
    echo "Done with SOBDetector."
    date
    
    echo "Making info table..."
    module load bcftools/{params.ver_bcftools}
    bcftools query -f '%INFO/numF1R2Alt\\t%INFO/numF2R1Alt\\t%INFO/numF1R2Ref\\t%INFO/numF2R1Ref\\t%INFO/numF1R2Other\\t%INFO/numF2R1Other\\t%INFO/SOB\\n' "{output.pass2_vcf}" | \
      awk '{{if ($1 != "."){{tum_alt=$1+$2; tum_depth=$1+$2+$3+$4+$5+$6; if (tum_depth==0){{tum_af=1}} else {{tum_af=tum_alt/tum_depth }}; print tum_alt,tum_depth,tum_af,$7}}}}' > "{output.pass2_info}"
    echo "Done making info table.!"
    date

    echo "Filtering out artifacts..."
    
    if [ "{wildcards.vc_outdir}" == "{config[output_params][MERGED_SOMATIC_OUTDIR]}" ]; then
        echo "... and adding 'set' annotation back from merged variants..."
        bgzip --threads $((SLURM_CPUS_PER_TASK - 1)) -c "{input.vcf}" > "{input.vcf}.gz"
        bcftools index -f -t "{input.vcf}.gz"
        
        bgzip --threads $((SLURM_CPUS_PER_TASK - 1)) -c "{output.pass2_vcf}" > "{output.pass2_vcf}.gz"
        bcftools index -f -t "{output.pass2_vcf}.gz"
        
        bcftools annotate -a "{input.vcf}.gz" -c "INFO/set" -e 'INFO/pArtifact < 0.05' -Oz -o {output.filtered_vcf} {output.pass2_vcf}.gz
    else
        bcftools filter -e 'INFO/pArtifact < 0.05' -Oz -o {output.filtered_vcf} {output.pass2_vcf}
        bcftools index -f -t {output.filtered_vcf}
    fi
    
    echo "Done."
    date
    """

rule sobdetect_metrics:
  input: pass1_vcf=expand(os.path.join(SOBDetector_out,"{{vc_outdir}}","pass1","{samples}.sobdetect.vcf"), samples=ffpe_sample_list),
         pass2_vcf=expand(os.path.join(SOBDetector_out,"{{vc_outdir}}","pass2","{samples}.sobdetect.vcf"), samples=ffpe_sample_list)
  output: count_table=os.path.join(SOBDetector_out,"{vc_outdir}","metrics","variant_count_table.txt"),
          full_metric_table=os.path.join(SOBDetector_out,"{vc_outdir}","metrics","all_metrics.txt")
  params: ver_bcftools=config['tools']['bcftools']['version'],
          rname="sobdetect_metrics"
  shell:
    """
    echo -e "#ID\\tDefaultParam\\tCohortParam\\tTotalVariants" > {output.count_table}
    echo -e "#SAMPLE_ID\\tParam\\tCHROM\\tPOS\\tnumF1R2Alt\\tnumF2R1Alt\\tnumF1R2Ref\\tnumF2R1Ref\\tnumF1R2Other\\tnumF2R1Other\\tSOB\\tpArtifact\\tFS\\tSOR\\tTLOD\\tReadPosRankSum" > {output.full_metric_table}
    
    P1FILES=({input.pass1_vcf})
    P2FILES=({input.pass2_vcf})
    module load bcftools/{params.ver_bcftools}
    date
    for (( i=0; i<${{#P1FILES[@]}}; i++ )); do
      MYID=$(basename -s ".sobdetect.vcf" ${{P1FILES[$i]}})
      echo "Collecting metrics from $MYID..."
      total_count=$(grep -v ^# ${{P1FILES[$i]}} | wc -l)
      count_1p=$(bcftools query -f '%INFO/pArtifact\n' ${{P1FILES[$i]}} | awk '{{if ($1 != "." && $1 < 0.05){{print}}}}' | wc -l)
      count_2p=$(bcftools query -f '%INFO/pArtifact\n' ${{P2FILES[$i]}} | awk '{{if ($1 != "." && $1 < 0.05){{print}}}}' | wc -l)
      
      echo -e "$MYID\\t$count_1p\\t$count_2p\\t$total_count" >> {output.count_table}
      
      bcftools query -f '%CHROM\\t%POS\\t%INFO/numF1R2Alt\\t%INFO/numF2R1Alt\\t%INFO/numF1R2Ref\\t%INFO/numF2R1Ref\\t%INFO/numF1R2Other\\t%INFO/numF2R1Other\\t%INFO/SOB\\t%INFO/pArtifact\n' ${{P1FILES[$i]}} | awk -v id=$MYID 'BEGIN{{OFS="\t"}}{{print id,"PASS_1",$0}}' >> {output.full_metric_table}
      bcftools query -f '%CHROM\\t%POS\\t%INFO/numF1R2Alt\\t%INFO/numF2R1Alt\\t%INFO/numF1R2Ref\\t%INFO/numF2R1Ref\\t%INFO/numF1R2Other\\t%INFO/numF2R1Other\\t%INFO/SOB\\t%INFO/pArtifact\n' ${{P2FILES[$i]}} | awk -v id=$MYID 'BEGIN{{OFS="\t"}}{{print id,"PASS_2",$0}}' >> {output.full_metric_table}
    done
    
    echo "Done"
    date
    """

rule ffpefilter_mafs:
  input: filtered_vcf=os.path.join(SOBDetector_out,"{vc_outdir}","pass2","{samples}.artifact_filtered.vcf.gz"),
         vcf2maf_script=VCF2MAF_WRAPPER
  output: maf=os.path.join(output_somatic_base,SOBDetector_out,"{vc_outdir}","maf","{samples}.maf")
  params: tumorsample="{samples}",genome=config['references']['MAF_GENOME'],filtervcf=config['references']['MAF_FILTERVCF'],rname="pl:vcf2maf"
  shell:
    """
    date
    echo "Converting to MAF..."
    bash {input.vcf2maf_script} --vcf {input.filtered_vcf} --maf {output.maf} --tid {params.tumorsample} --genome {params.genome} --threads "$((SLURM_CPUS_PER_TASK-1))" --info "set"
    echo "Done converting to MAF..."
    date
    """
  
rule collect_ffpefilter_mafs:
  input: mafs=expand(os.path.join(SOBDetector_out,"{{vc_outdir}}","maf","{samples}"+".maf"), samples=ffpe_sample_list)
  output: maf=os.path.join(output_somatic_base,SOBDetector_out,"{vc_outdir}","cohort_summary","all_somatic_variants.maf")
  params: rname="combine_maf"
  shell:"""    
    date
    echo "Combining MAFs..."
    awk 'FNR==1 && NR!=1 {{ while (/^#/||/^Hugo_Symbol/) getline; }} 1 {{print}}' {input.mafs} > {output.maf}
    echo "Done..."
    date
  """
  
# 
# rule freec_exome_somatic_pass1:
#   input: normal = lambda w: [os.path.join(output_bamdir, pairs_dict[w.samples] + ".recal.bam")],
#          tumor=os.path.join(output_bamdir, "{samples}.recal.bam"),
#   output: cnvs=os.path.join(output_somatic_cnv,"freec_out","pass1","{samples}.recal.bam_CNVs.p.value.txt"),
#   params: targets=exome_targets_bed,normalsample=lambda w: [pairs_dict[w.samples]],tumorsample="{samples}",
#           fasta=config['references']['GENOME'],lengths=config['references']['FREECLENGTHS'],
#           chroms=config['references']['FREECCHROMS'],
#           pile=config['references']['FREECPILEUP'],
#           snps=config['references']['FREECSNPS'],
#           config_script=config['scripts']['freec_p1_config'],
#           sig_script=config['scripts']['freec_significance'],
#           plot_script=config['scripts']['freec_plot'],
#           rname="freec1"
#   shell: """
#          myoutdir="$(dirname {output.cnvs})/{params.tumorsample}"
#          if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi
#          
#          perl "{params.config_script}" "$myoutdir" {params.lengths} {params.chroms} {input.tumor} {input.normal} {params.pile} {params.fasta} {params.snps} {params.targets}
#          module load freec/11.5
#          module load samtools/1.9
#          module load bedtools/2.27.1
#          freec -conf "$myoutdir/freec_exome_config.txt"
#          
#          module load R/3.6.1
#          cat "{params.sig_script}" | R --slave --args $myoutdir/{params.tumorsample}.recal.bam_CNVs $myoutdir/{params.tumorsample}.recal.bam_ratio.txt
#          mv $myoutdir/{params.tumorsample}.recal.bam_CNVs.p.value.txt {output.cnvs}
#          cat "{params.plot_script}" | R --slave --args 2 $myoutdir/{params.tumorsample}.recal.bam_ratio.txt $myoutdir/{params.tumorsample}.recal.bam_BAF.txt
#          """
# 
# rule sequenza:
#   input: freeccnvs=os.path.join(output_somatic_cnv,"freec_out","pass1/{samples}.recal.bam_CNVs.p.value.txt"),
#   output: fit=os.path.join(output_somatic_cnv,"sequenza_out","{samples}_alternative_solutions.txt"),
#   params: normalsample=lambda w: [pairs_dict[w.samples]],tumorsample="{samples}",
#           gc=config['references']['SEQUENZAGC'],
#           run_script=config['scripts']['run_sequenza'],
#           rname="sequenza"
#   threads: 8
#   shell: """
#          myoutdir="$(dirname {output.fit})/{params.tumorsample}"
#          if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi
#          
#          module load sequenza-utils/2.2.0
#          module load samtools/1.9
#          gzip -c "$(dirname {input.freeccnvs})/{params.tumorsample}/{params.normalsample}.recal.bam_minipileup.pileup" > "$myoutdir/{params.normalsample}.recal.bam_minipileup.pileup.gz"
#          gzip -c "$(dirname {input.freeccnvs})/{params.tumorsample}/{params.tumorsample}.recal.bam_minipileup.pileup" > "$myoutdir/{params.tumorsample}.recal.bam_minipileup.pileup.gz"
#          sequenza-utils bam2seqz -p -gc {params.gc} -n "$myoutdir/{params.normalsample}.recal.bam_minipileup.pileup.gz" -t "$myoutdir/{params.tumorsample}.recal.bam_minipileup.pileup.gz" | gzip > "$myoutdir/{params.tumorsample}.seqz.gz"
#          sequenza-utils seqz_binning -w 100 -s "$myoutdir/{params.tumorsample}.seqz.gz" | gzip > "$myoutdir/{params.tumorsample}.bin100.seqz.gz"
#          
#          module load R/3.6.1
#          Rscript "{params.run_script}" "$myoutdir/{params.tumorsample}.bin100.seqz.gz" "$myoutdir" "{params.normalsample}+{params.tumorsample}" $((SLURM_CPUS_PER_TASK-1))
#          mv "$myoutdir/{params.normalsample}+{params.tumorsample}_alternative_solutions.txt" "{output.fit}"
#          """
# 
# rule freec_exome_somatic_pass2:
#   input: normal = lambda w: [os.path.join(output_bamdir, pairs_dict[w.samples] + ".recal.bam")],
#          tumor=os.path.join(output_bamdir, "{samples}.recal.bam"),
#          fit=os.path.join(output_somatic_cnv,"sequenza_out","{samples}_alternative_solutions.txt"),
#   output: cnvs=os.path.join(output_somatic_cnv,"freec_out","pass2","{samples}.recal.bam_CNVs.p.value.txt"),
#   params: targets=exome_targets_bed,normalsample=lambda w: [pairs_dict[w.samples]],tumorsample="{samples}",
#           fasta=config['references']['GENOME'],
#           lengths=config['references']['FREECLENGTHS'],
#           chroms=config['references']['FREECCHROMS'],
#           pile=config['references']['FREECPILEUP'],
#           snps=config['references']['FREECSNPS'],
#           config_script=config['scripts']['freec_p2_config'],
#           sig_script=config['scripts']['freec_significance'],
#           plot_script=config['scripts']['freec_plot'],
#           rname="pl:freec"
#   shell: """
#          myoutdir="$(dirname {output.cnvs})/{params.tumorsample}"
#          if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi
#          
#          perl /data/CCBR_Pipeliner/4.0.2/Pipeliner/Results-template/Scripts/make_freec_pass2_exome_tn_config.pl "$myoutdir" {params.lengths} {params.chroms} {input.tumor} {input.normal} {params.pile} {params.fasta} {params.snps} {params.targets} {input.fit}
#          module load freec/11.5
#          module load samtools/1.9
#          module load bedtools/2.27.1
#          freec -conf "$myoutdir/freec_exome_config.txt"
#          freec -conf "$myoutdir/freec_exome_config.txt"
#          module load R/3.6.1
#          cat "{params.sig_script}" | R --slave --args $myoutdir/{params.tumorsample}.recal.bam_CNVs $myoutdir/{params.tumorsample}.recal.bam_ratio.txt
#          mv $myoutdir/{params.tumorsample}.recal.bam_CNVs.p.value.txt {output.cnvs}
#          cat "{params.plot_script}" | R --slave --args 2 $myoutdir/{params.tumorsample}.recal.bam_ratio.txt $myoutdir/{params.tumorsample}.recal.bam_BAF.txt
#          """

# rule strelka_merge:
#   input: vcf="strelka_out/{samples}/{samples}.vcf",
#          names="strelka_out/{samples}.samples",
#   output: rehead="strelka_out/{samples}/{samples}.rehead.vcf",
#   params: dir="/data/MA_shared/justin_wes_pipe/paired_calls",normalsample=lambda w: [pairs_dict[w.samples]],tumorsample="{samples}",fasta=config['references']['GENOME'],rname="strelka_merge"
#   shell: """
#          module load samtools/1.6
#          bcftools reheader -o {output.rehead} -s {input.names} {input.vcf}
#          """

# rule raw_merge:
#   input: strelka="strelka_out/{samples}/{samples}.rehead.vcf",
#          mutect="mutect_out/{samples}.vcf",
#          mutect2="mutect2_out/{samples}.filtered.vcf",
#   output: vcf="superfreq/vcfs/{samples}.allRaw.vcf",
#   params: dir="paired_calls",normalsample=lambda w: [pairs_dict[w.samples]],tumorsample="{samples}",fasta=config['references']['GENOME'],rname="merge_raw"
#   shell: """
#          mkdir -p superfreq
#          mkdir -p superfreq/vcfs
#          module load GATK/3.8-1
#          java -Xmx48g -Djava.io.tmpdir=/lscratch/$SLURM_JOBID -jar $GATK_JAR -T CombineVariants -R {params.fasta} -nt 4 --filteredrecordsmergetype KEEP_UNCONDITIONAL --genotypemergeoption PRIORITIZE --rod_priority_list mutect2,mutect,strelka --minimumN 1 -o {output.vcf} --variant:mutect {input.mutect} --variant:strelka {input.strelka} --variant:mutect2 {input.mutect2}
#          """

# rule pyclone:
#   input: fit="sequenza_out/{samples}"+"_alternative_solutions.txt",
#   output: vcf="pyclone/{samples}/config.yaml",
#   params: normalsample=lambda w: [pairs_dict[w.samples]],tumorsample="{samples}",fasta=config['references']['GENOME'],rname="pyclone"
#   shell: """
#          perl /data/MA_shared/justin_wes_pipe/paired_calls/pyclone/generate_pyclone_input.pl /data/MA_shared/justin_wes_pipe/combined_variants/all_merged_filtered.maf sequenza_out/{params.tumorsample}/{params.normalsample}+{params.tumorsample}_segments.txt {params.tumorsample}
#          module load pyclone
#          mkdir -p pyclone/{params.tumorsample}
#          purity=$(cat sequenza_out/{params.tumorsample}_alternative_solutions.txt | cut -f1 | head -2 | tail -1)
#          PyClone run_analysis_pipeline --in_files pyclone/{params.tumorsample}.pyclone.input --thin=10 --working_dir pyclone/{params.tumorsample} --tumour_contents $purity --samples {params.tumorsample} --plot_file_format pdf --burnin 10000 --density pyclone_binomial --num_iters 1000000
#          """

rule haplotypecaller:
    input: 
        bam=os.path.join(output_bamdir,"final_bams","{samples}.bam"),
        bai=os.path.join(output_bamdir,"final_bams","{samples}.bai"),
    output:
        gzvcf = temp(os.path.join(output_germline_base,"gVCFs","{samples}.{chroms}.g.vcf.gz")),
        index = temp(os.path.join(output_germline_base,"gVCFs","{samples}.{chroms}.g.vcf.gz.tbi")),
    params: 
        sample = "{samples}",rname = "hapcaller",genome = config['references']['GENOME'],snpsites=config['references']['DBSNP'], chrom="{chroms}"
    shell:
        """
        myoutdir="$(dirname {output.gzvcf})"
        if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi
         
        module load GATK/4.1.4.1
        gatk --java-options '-Xmx24g' HaplotypeCaller --reference {params.genome} --input {input.bam} --use-jdk-inflater --use-jdk-deflater --emit-ref-confidence GVCF --annotation-group StandardAnnotation --annotation-group AS_StandardAnnotation --dbsnp {params.snpsites} --output {output.gzvcf} --intervals {params.chrom} --max-alternate-alleles 3
        """

# rule listgvcfs:
#     input: 
#         gzvcf = expand(os.path.join("gVCFs/{samples}.{{chroms}}.g.vcf.gz",samples=samples)),
#         index = expand(os.path.join("gVCFs/{samples}.{{chroms}}.g.vcf.gz.tbi",samples=samples),
#     output:
#         list = "gVCFs/gVCFs.{chroms}.list"
#     params: 
#         rname = "listgvcfs",genome = config['references']['GENOME'],chrom="{chroms}"
#     shell:
#         """
#         ls gVCFs/*.{params.chrom}.g.vcf.gz > {output.list}
#         """

rule mergegvcfs:
    input: gzvcf = expand(os.path.join(output_germline_base,"gVCFs","{samples}.{{chroms}}.g.vcf.gz"),samples=samples),
           index = expand(os.path.join(output_germline_base,"gVCFs","{samples}.{{chroms}}.g.vcf.gz.tbi"),samples=samples),
           # list = "gVCFs/gVCFs.{chroms}.list",
    output:
        gzvcf = os.path.join(output_germline_base,"gVCFs","merged.{chroms}.g.vcf.gz"),
        index = os.path.join(output_germline_base,"gVCFs","merged.{chroms}.g.vcf.gz.tbi"),
    params: 
        rname = "mergegvcfs",genome = config['references']['GENOME']
    shell:
        """
        input_str="--variant $(echo "{input.gzvcf}" | sed -e 's/ / --variant /g')"
        
        module load GATK/4.1.4.1
        gatk --java-options '-Xmx24g' CombineGVCFs --reference {params.genome} --annotation-group StandardAnnotation --annotation-group AS_StandardAnnotation $input_str --output {output.gzvcf} --intervals {wildcards.chroms} --use-jdk-inflater --use-jdk-deflater
        """

rule genotype:
    input: 
        gzvcf = os.path.join(output_germline_base,"gVCFs","merged.{chroms}.g.vcf.gz"),
        index = os.path.join(output_germline_base,"gVCFs","merged.{chroms}.g.vcf.gz.tbi"),
    output:
        vcf = os.path.join(output_germline_base,"VCF","by_chrom","raw_variants.{chroms}.vcf.gz"),
    params:
        rname = "genotype",genome = config['references']['GENOME'],snpsites=config['references']['DBSNP'],chr="{chroms}"
    shell:
        """
        myoutdir="$(dirname {output.vcf})"
        if [ ! -d "$myoutdir" ]; then mkdir -p "$myoutdir"; fi
        
        module load GATK/4.1.4.1
        gatk --java-options '-Xmx96g' GenotypeGVCFs --reference {params.genome} --use-jdk-inflater --use-jdk-deflater --annotation-group StandardAnnotation --annotation-group AS_StandardAnnotation --dbsnp {params.snpsites} --output {output.vcf} --variant {input.gzvcf} --intervals {params.chr}
        """

rule germline_merge_chrom:
    input:
        expand(os.path.join(output_germline_base,"VCF","by_chrom","raw_variants.{chroms}.vcf.gz"), chroms=chroms),
    output:
        vcf = os.path.join(output_germline_base,"VCF","raw_variants.vcf.gz"),
        list = os.path.join(output_germline_base,"VCF","by_chrom","raw_variants_byChrom.list"),
    params:
        rname = "merge_chrom", genome = config['references']['GENOME']
    shell:
        """
        ls -d $(dirname "{output.list}")/raw_variants.*.vcf.gz > "{output.list}"
        module load GATK/4.1.7.0
        gatk MergeVcfs -R {params.genome} --INPUT="{output.list}" --OUTPUT={output.vcf}
        """

rule Gatk_SelectVariants:
	input: vcf=os.path.join(output_germline_base,"VCF","raw_variants.vcf.gz"),
	output: vcf=os.path.join(output_germline_base,"VCF","{samples}.germline.vcf.gz")
	params: genome=config['references']['GENOME'], Sname = "{samples}", rname="varselect",ver_gatk=config['tools']['gatk4']['version'],targets=exome_targets_bed
	shell:"""
          module load GATK/{params.ver_gatk}
          gatk SelectVariants -R {params.genome} --intervals {params.targets} --variant {input.vcf} --sample-name {params.Sname} --exclude-filtered --exclude-non-variants --output {output.vcf}
	      """

# rule hla:
#     input: 
#         bam="HLA/bams/{samplesb}.recal.bam",
#     output: 
#         hla = "HLA/{samplesb}/hla/R1_bestguess_G.txt",
#     params: 
#         rname = "hla",
#         hladir = "HLA",
#         samplename="{samplesb}"
#     shell: 
#         """
#         module load HLA-PRG-LA/1.0.1
#         mkdir -p HLA
#         HLA-LA.pl --BAM {input.bam} --graph PRG_MHC_GRCh38_withIMGT  --sampleID {params.samplename} --maxThreads 7 --workingDir {params.hladir}
#         """
# 
# rule polysolver:
#       input:  bam="bams/{samples}.recal.bam",
#       output: out="polysolver/{samples}/winners.hla.nofreq.txt",
#       params: sample = "{samples}",normalsample=lambda w: [pairs_dict[w.samples]],rname="polysolver"
#       shell:  """
#               mkdir -p {params.sample}
#               module load singularity
#               export SINGULARITY_CACHEDIR=/data/lackjb/.singularity
#               singularity exec -B "$PWD:/data2/" app/ccbr_polysolver_v0.0.1-beta.sif bash /home/polysolver/scripts/shell_call_hla_type BAM/{params.normalsample}.recal.bam Unknown 0 hg19 STDFQ 0 {params.sample}
#               """
# 
# rule hlamut:
#       input:  winners="{samples}/winners.hla.nofreq.txt",
#               tumor="BAM/{samples}.recal.bam",
#               normal= lambda w: [join("BAM", pairs_dict[w.samples] + ".recal.bam")],
#       output: out="{samples}/hla_mut.tar.gz",
#       params: genome=config['references']['GENOME'],normalsample=lambda w: [pairs_dict[w.samples]],tumorsample="{samples}",rname="hlamut"
#       shell:  """
#               module load singularity
#               export SINGULARITY_CACHEDIR=/data/lackjb/.singularity
#               cd {params.tumorsample}
#               ln -s ../{input.tumor} {params.tumorsample}.recal.bam
#               ln -s ../BAM/{params.tumorsample}.recal.bai {params.tumorsample}.recal.bai
#               ln -s ../{input.normal} {params.normalsample}.recal.bam
#               ln -s ../BAM/{params.normalsample}.recal.bai {params.normalsample}.recal.bai
#               singularity exec -B "$PWD:/data2/,/data/MA_shared/justin_wes_pipe" /data/MA_shared/justin_wes_pipe/polysolver/app/ccbr_polysolver_v0.0.1-beta.sif bash /home/polysolver/scripts/shell_call_hla_mutations_from_type {params.normalsample}.recal.bam {params.tumorsample}.recal.bam winners.hla.nofreq.txt hg19 STDFQ . {params.tumorsample}
#               """
# 
# rule annothla:
#       input:  out="{samples}/hla_mut.tar.gz",
#       output: out="{samples}/{samples}.mutect.filtered.annotated",
#       params: genome=config['references']['GENOME'],normalsample=lambda w: [pairs_dict[w.samples]],tumorsample="{samples}",rname="annothla"
#       shell:  """
#               module load singularity
#               export SINGULARITY_CACHEDIR=/data/lackjb/.singularity
#               cd {params.tumorsample}
#               singularity exec -B "$PWD:/data2/,/data/MA_shared/justin_wes_pipe" /data/MA_shared/justin_wes_pipe/polysolver/app/ccbr_polysolver_v0.0.1-beta.sif bash /home/polysolver/scripts/shell_annotate_hla_mutations {params.tumorsample} hla_mut.tar.gz .
#               """
#
#
#


# Quality-control related rules
rule fc_lane:
    """
    Quality-control step to get flowcell and lane information from FastQ file.
    FastQ files generated with older versions of Casava or downloaded from
    SRA have a different format than newer FastQ files generated with the
    current version of Casava. It is worth noting that FastQ files downloaded from SRA
    or FastQ files generated with Casava version < 1.8 do not have Flowcell
    IDs in its sequence indentifer. If a FastQ file does not have Flowcell IDs,
    the Machine or Instrument ID is grabbed instead.
    @Input:
        Raw FastQ R1 file (scatter)
    @Output:
        Text file containing information about the FastQ file
    """
    input:
        r1 = os.path.join(input_fqdir, "{samples}.R1.fastq.gz"),
    output:
        txt = os.path.join(output_fqdir,"{samples}.fastq.info.txt")
    params:
        rname = 'pl:fc_lane',
        get_flowcell_lanes = os.path.join("scripts", "get_flowcell_lanes.py"),
    shell: """
    module load python/2.7
    python {params.get_flowcell_lanes} \\
        {input.r1} \\
        {wildcards.samples} > {output.txt}
    """


rule fastq_screen:
    """
    Quality-control step to screen for different sources of contamination.
    FastQ Screen compares your sequencing data to a set of different reference
    genomes to determine if there is contamination. It allows a user to see if
    the composition of your library matches what you expect.
    @Input:
        Trimmed FastQ files (scatter)
    @Output:
        FastQ Screen report and logfiles
    """
    input:
        fq1 = os.path.join(output_fqdir,"{samples}.R1.trimmed.fastq.gz"),
        fq2 = os.path.join(output_fqdir,"{samples}.R2.trimmed.fastq.gz")
    output:
        txt1 = os.path.join(output_qcdir,"FQscreen","{samples}.R1.trimmed_screen.txt"),
        txt2 = os.path.join(output_qcdir,"FQscreen","{samples}.R2.trimmed_screen.txt"),
        png1 = os.path.join(output_qcdir,"FQscreen","{samples}.R1.trimmed_screen.png"),
        png2 = os.path.join(output_qcdir,"FQscreen","{samples}.R2.trimmed_screen.png")
    params:
        rname  = "pl:fqscreen",
        outdir = os.path.join(output_qcdir,"FQscreen"),
        # Exposed Parameters: modify resources/fastq_screen.conf to change 
        # default locations to bowtie2 indices
        fastq_screen_config = config['references']['FASTQ_SCREEN_CONFIG'],
    threads: 24
    shell: """
    module load fastq_screen/0.14.1
    fastq_screen --conf {params.fastq_screen_config} \\
        --outdir {params.outdir} \\
        --threads {threads} \\
        --subset 1000000 \\
        --aligner bowtie2 \\
        --force \\
        {input.fq1} {input.fq2}
    """


rule kraken:
    """
    Quality-control step to assess for potential sources of microbial contamination.
    If there are high levels of microbial contamination, Kraken will provide an
    estimation of the taxonomic composition. Kraken is used in conjunction with
    Krona to produce an interactive reports.
    @Input:
        Trimmed FastQ files (scatter)
    @Output:
        Kraken logfile and interative krona report
    """
    input:
        fq1 = os.path.join(output_fqdir,"{samples}.R1.trimmed.fastq.gz"),
        fq2 = os.path.join(output_fqdir,"{samples}.R2.trimmed.fastq.gz")
    output:
        out  = os.path.join(output_qcdir,"kraken","{samples}.trimmed.kraken_bacteria.out.txt"),
        taxa = os.path.join(output_qcdir,"kraken","{samples}.trimmed.kraken_bacteria.taxa.txt"),
        html = os.path.join(output_qcdir,"kraken","{samples}.trimmed.kraken_bacteria.krona.html"),
    params:
        rname  ='pl:kraken',
        outdir = os.path.join(output_qcdir, "kraken"),
        bacdb  = config['references']['KRAKENBACDB'],
    threads: 24
    shell: """
    module load kraken/2.1.2
    module load kronatools/2.8
    # Copy kraken2 db to local node storage to reduce filesystem strain
    cp -rv {params.bacdb} /lscratch/$SLURM_JOBID/
    kdb_base=$(basename {params.bacdb})
    kraken2 --db /lscratch/$SLURM_JOBID/${{kdb_base}} \\
        --threads {threads} --report {output.taxa} \\
        --output {output.out} \\
        --gzip-compressed \\
        --paired {input.fq1} {input.fq2}
    # Generate Krona Report
    cut -f2,3 {output.out} | \\
        ktImportTaxonomy - -o {output.html}
    """


rule fastqc_bam:
    """
    Quality-control step to assess sequencing quality of each sample.
    FastQC generates a set of basic statistics to identify problems
    that can arise during sequencing or library preparation.
    @Input:
        Recalibrated BAM file (scatter)
    @Output:
        FastQC report and zip file containing sequencing quality information
    """
    input:
        bam = os.path.join(output_bamdir,"final_bams","{samples}.bam"),
    output:
        zipfile =  os.path.join(output_qcdir,"{samples}.recal_fastqc.zip"),
        report  =  os.path.join(output_qcdir,"{samples}.recal_fastqc.html")
    params:
        outdir = output_qcdir,
        rname  = "fastqc_bam",
    message: "Running FastQC with {threads} threads on '{input}' input file"
    threads: 8
    shell: """
    module load fastqc/0.11.9
    fastqc -t {threads} \\
        -f bam \\
        -o {params.outdir} \\
        {input.bam} 
    """


rule qualimap_bamqc:
    """
    Quality-control step to assess various post-alignment metrics 
    and a secondary method to calculate insert size. Please see
    QualiMap's website for more information about BAM QC:
    http://qualimap.conesalab.org/
    @Input:
        Recalibrated BAM file (scatter)
    @Output:
        Report containing post-aligment quality-control metrics
    """
    input:
        bam  = os.path.join(output_bamdir,"final_bams","{samples}.bam"),
    output: 
        txt  = os.path.join(output_qcdir,"{samples}","genome_results.txt"),
        html = os.path.join(output_qcdir,"{samples}","qualimapReport.html")
    params:
        outdir = os.path.join(output_qcdir, "{samples}"),
        rname  = "qualibam"
    message: "Running QualiMap BAM QC with {threads} threads on '{input}' input file"
    threads: 8
    shell: """
    module load qualimap/2.2.1
    unset DISPLAY
    qualimap bamqc -bam {input.bam} \\
        --java-mem-size=48G \\
        -c -gd hg19 -ip \\
        -outdir {params.outdir} \\
        -outformat HTML \\
        -nt {threads} \\
        --skip-duplicated \\
        -nw 500 \\
        -p NON-STRAND-SPECIFIC
    """


rule samtools_flagstats:
    """
    Quality-control step to assess alignment quality. Flagstat provides 
    counts for each of 13 categories based primarily on bit flags in the 
    FLAG field. Information on the meaning of the flags is given in the 
    SAM specification: https://samtools.github.io/hts-specs/SAMv1.pdf
    @Input:
        Recalibrated BAM file (scatter)
    @Output:
        Text file containing alignment statistics
    """
    input:
        bam  = os.path.join(output_bamdir,"final_bams","{samples}.bam"),
    output:
        txt  = os.path.join(output_qcdir,"{samples}.samtools_flagstat.txt")
    params: 
        rname = "samtools_flagstats"
    message: "Running SAMtools flagstat on '{input}' input file"
    shell: """
    module load samtools/1.12
    samtools flagstat {input.bam} > {output.txt}
    """


rule vcftools:
    """
    Quality-control step to calculates a measure of heterozygosity on 
    a per-individual basis. The inbreeding coefficient, F, is estimated
    for each individual using a method of moments. Please see VCFtools
    documentation for more information: 
    https://vcftools.github.io/man_latest.html
    @Input:
        Multi-sample gVCF file (indirect-gather-due-to-aggregation)
    @Output:
        Text file containing a measure of heterozygosity
    """
    input: 
        vcf = os.path.join(output_germline_base,"VCF","raw_variants.vcf.gz"),
    output: 
        het = os.path.join(output_qcdir,"raw_variants.het"),
    params: 
        prefix = os.path.join(output_qcdir,"raw_variants"),
        rname  = "vcftools",
    message: "Running VCFtools on '{input.vcf}' input file"
    shell: """
    module load vcftools/0.1.16
    vcftools --gzvcf {input.vcf} --het --out {params.prefix}
    """


rule collectvariantcallmetrics:
    """
    Quality-control step to collect summary metrics about snps and indels
    called in a multisample VCF file. Please see the Broad's documentation
    for more information about each field in the generated log file:
    https://broadinstitute.github.io/picard/picard-metric-definitions.html
    @Input:
        Multi-sample gVCF file (indirect-gather-due-to-aggregation)
    @Output:
        Text file containing a collection of metrics relating to snps and indels 
    """
    input: 
        vcf = os.path.join(output_germline_base,"VCF","raw_variants.vcf.gz"),
    output: 
        metrics = os.path.join(output_qcdir,"raw_variants.variant_calling_detail_metrics"),
    params: 
        dbsnp=config['references']['DBSNP'],
        prefix = os.path.join(output_qcdir,"raw_variants"),
        rname="varcallmetrics",
    message: "Running Picard CollectVariantCallingMetrics on '{input.vcf}' input file"
    shell: """
    module load picard/2.20.8
    java -Xmx24g -jar ${{PICARDJARPATH}}/picard.jar \\
        CollectVariantCallingMetrics \\
        INPUT={input.vcf} \\
        OUTPUT={params.prefix} \\
        DBSNP={params.dbsnp} Validation_Stringency=SILENT
    """


rule bcftools_stats:
    """
    Quality-control step to collect summary statistics from bcftools stats.
    When bcftools stats is run with one VCF file then stats by non-reference
    allele frequency, depth distribution, stats by quality and per-sample 
    counts, singleton statsistics are calculated. Please see bcftools' 
    documentation for more information: 
    http://samtools.github.io/bcftools/bcftools.html#stats
    @Input:
        Per sample gVCF file (scatter)
    @Output:
        Text file containing a collection of summary statistics
    """
    input: 
        vcf = os.path.join(output_germline_base,"VCF","{samples}.germline.vcf.gz"),
    output: 
        txt = os.path.join(output_qcdir,"{samples}.germline.bcftools_stats.txt"),
    params: 
        rname="bcfstats",
    shell: """
    module load bcftools/1.9
    bcftools stats {input.vcf} > {output.txt}
    """

rule gatk_varianteval:
    """
    Quality-control step to calculate various quality control metrics from a 
    variant callset. These metrics include the number of raw or filtered SNP 
    counts; ratio of transition mutations to transversions; concordance of a
    particular sample's calls to a genotyping chip; number of s per sample.
    Please see GATK's documentation for more information: 
    https://gatk.broadinstitute.org/hc/en-us/articles/360040507171-VariantEval
    @Input:
        Per sample gVCF file (scatter)
    @Output:
        Evaluation table containing a collection of summary statistics
    """
    input: 
        vcf = os.path.join(output_germline_base,"VCF","{samples}.germline.vcf.gz"), 
    output: 
        grp = os.path.join(output_qcdir,"{samples}.germline.eval.grp"),
    params:
        rname    = "vareval",
        genome   = config['references']['GENOME'],
        dbsnp    = config['references']['DBSNP'],
        ver_gatk = config['tools']['gatk4']['version']
    threads: 16
    shell: """
    module load GATK/{params.ver_gatk}
    gatk --java-options '-Xmx12g -XX:ParallelGCThreads={threads}' VariantEval \\
        -R {params.genome} \\
        -O {output.grp} \\
        --dbsnp {params.dbsnp} \\
        --eval {input.vcf} 
    """


rule snpeff:
    """
    Data processing and quality-control step to annotate variants, predict its
    functional effects, and collect various summary statistics about variants and
    their annotations. Please see SnpEff's documentation for more information: 
    https://pcingola.github.io/SnpEff/
    @Input:
        Per sample gVCF file (scatter)
    @Output:
        Evaluation table containing a collection of summary statistics
    """
    input:  
        vcf = os.path.join(output_germline_base,"VCF","{samples}.germline.vcf.gz")
    output: 
        vcf  = os.path.join(output_qcdir,"{samples}.germline.snpeff.ann.vcf"),
        csv  = os.path.join(output_qcdir,"{samples}.germline.snpeff.ann.csv"),
        html = os.path.join(output_qcdir,"{samples}.germline.snpeff.ann.html"),
    params: 
        rname  = "snpeff",
        genome = config['references']['SNPEFF_GENOME'],
        config = config['references']['SNPEFF_CONFIG']
    shell: """
    module load snpEff/4.3t
    java -Xmx12g -jar $SNPEFF_JAR \\
        -v -canon -c {params.config} \\
        -csvstats {output.csv} \\
        -stats {output.html} \\
        {params.genome} \\
        {input.vcf} > {output.vcf}
    """
  
rule somalier_relatedness:
    input:
        somalier=expand(os.path.join(output_germline_base,"somalier","{samples}.somalier"), samples=samples),
    output:
        somalierPairs=os.path.join(output_germline_base,"somalier","relatedness.pairs.tsv"),
        somalierSamples=os.path.join(output_germline_base,"somalier","relatedness.samples.tsv"),
        somalierAncestry=os.path.join(output_germline_base,"somalier","ancestry.tsv"),
    params: ancestry_db=config['references']['SOMALIER']['ANCESTRY_DB'],container=config['references']['SOMALIER']['CONTAINER'],
            sites_vcf=config['references']['SOMALIER']['SITES_VCF'],genomeFasta=config['references']['GENOME'],rname="somalier_relatedness"
    shell:  """
        module load singularity    
	    ANCESTRY_DB={params.ancestry_db}
        CONTAINER={params.container}
        GENOME_FASTA={params.genomeFasta}
        SITES_VCF={params.sites_vcf}
        OUT_DIR=$(dirname {output.somalierPairs}) #Need to set this path somewhere
        SOMALIER_CMDS="date;
                    somalier relate -o /out/relatedness /out/*.somalier;
                    somalier ancestry -o /out/ancestry --labels /refs/ancestry/ancestry-labels-1kg.tsv /refs/ancestry/*.somalier ++ /out/*.somalier;
                    echo 'Done';
                    date;"
            ## Run the commands in the image with binded paths to input/output files
            singularity exec --bind $GENOME_FASTA:/refs/genome.fa \
                                     --bind $GENOME_FASTA.fai:/refs/genome.fa.fai \
                                     --bind $SITES_VCF:/refs/sites.vcf.gz \
                                     --bind $SITES_VCF.tbi:/refs/sites.vcf.gz.tbi \
                                     --bind $ANCESTRY_DB:/refs/ancestry/ \
                                     --bind $OUT_DIR:/out \
                                     $CONTAINER \
                                     /bin/sh -c "$SOMALIER_CMDS"
            """

rule somalier_analysis:
    input:  somalierPairs=os.path.join(output_germline_base,"somalier","relatedness.pairs.tsv"),
            somalierSamples=os.path.join(output_germline_base,"somalier","relatedness.samples.tsv"),
            somalierAncestry=os.path.join(output_germline_base,"somalier","relatedness.pairs.tsv"),
    output: finalFileGender=os.path.join(output_germline_base,"predicted.genders.tsv"),
            finalFilePairs=os.path.join(output_germline_base,"predicted.pairs.tsv"),
            ancestoryPlot=os.path.join(output_germline_base,"sampleAncestryPCAPlot.html"),
            pairAncestoryHist=os.path.join(output_germline_base,"predictedPairsAncestry.pdf"),
    params: ver_R=config['tools']['R']['version'],
            script_path_gender=config['scripts']['genderPrediction'],
            script_path_samples=config['scripts']['combineSamples'],
            script_path_pca=config['scripts']['ancestry'],
            rname = "genderPrediction"
    shell: """
            module load R/{params.ver_R}
            
            Rscript {params.script_path_gender} {input.somalierSamples} {output.finalFileGender}
            
            Rscript {params.script_path_samples} {input.somalierPairs} {output.finalFilePairs}
            
            Rscript {params.script_path_pca} {input.somalierAncestry} {output.finalFilePairs} {output.ancestoryPlot} {output.pairAncestoryHist}
    """

